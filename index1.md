# 新尝试~使用随机森林进行装箱计算

## 概要：

本文将介绍如何使用机器学习训练订单及其装箱数据，并使用该模型对未训练过的订单进行装箱预测。

装箱计算是我司在顾客购物后，订单发货前的一个重要环节。顾客订购了众多大小不一的商品，要使用什么箱子装放客人的商品是一门学问。太大会导致顾客商品得不到保护，运费增加；太小也会破坏商品，或甚至装不下，需要更换箱子，效率低下，浪费时间。以往，我們设计专门的软件依据客人每张订单中商品的大小、依据可用箱子大小等，计算找到合适的箱子（可能多个不同类型的箱子），那计算逻辑也是复杂复杂的！

自上年公司策略改变，把仓库、发货等业务外包到配送商，装箱计算就不再需要我們操心了。不过又遇到另一个问题，因配送商依据配送件数收取我們操作费用，我們把订单数据送到他们，他们决定每张订单的装箱方案。经过几个月合作，发现他们的装箱费用要比我們以往未外包前要高。

如何才能监督他们？难度每月结算时，我們又要自己将整月的订单计算一遍？

重新计算一遍是一个绝对准确的办法，但是可能较费时喔，且要把原来用作装箱计算的软件逻辑做一些迁移。能否做个简单计算就可以知道配送商的装箱费用是否合理？例如大概知道以往的订单量及对应的装箱费用（假设以往的是一个基准），它们俩应该有一定线性关系。那么如果知道本月的订单量，应该就能推算到装箱费用。

上面的想法绝对是可行的。日常生活我們经常做同类的事情，例如你家电费突然高得离谱，你一定会找找原因，是夏天开多了空调吗？是新添加了大电器吗？还是供电局算错了？…可惜！可惜我没有以往装箱操作费用的信息！·#￥%@@@##...
我有什么？！我有以往订单的情况及其装箱方案。我想能否通过以往的装箱方案数据推算出未来订单的装箱方案？通过这个再换算估算的费用？嗯…我想应该可以。 

上面背景的废话说完，我們来进入主题。Talk is cheap! Show me the code~! 
先来看看原始数据的情况：

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/source_data.PNG)


让我们先对数据有一个大致的了解，如上图，数据中有订单编号(ordnum)，产品编号(prtnum)，产品装放的箱子编号(ctnnum)，产品装放的箱子类型(ctnsze)，在该箱子中装放该产品的数量(pckqty)，产品的规格信息(长untlen宽untwid高unthgt)。
一张订单的数据可能是在多行，一张订单可能有多个箱子，而每个箱子放置的产品可能有多样，所以一个箱子的数据也是多行。
其中箱子类型为Z的是整箱(即原厂生产的箱子，顾客订购数量大于或等于一个原厂箱子中产品的数量，所以不需要再装放在散箱中，直接整箱发出)，Z箱不是我们需要分析的数据，可以去掉。
注意：实际上最最最原始的数据也不是长这个样子，数据存放在不同的关系型数据表中。上面的文本文件source_data.csv已做了一定处理。

我们先定义我们的目标：
我们要通过每张订单订购的商品信息（例如订单订购了A产品n件+B产品m件），分析、学习其装箱方案（例如订单使用了1个M类型箱子+2个S类型箱子），产生模型。在未来，面对新的订单数据，我们期望通过此模型能猜出其装箱方案。

目标明确后，我们先来整理原始数据。整理原始数据又可以分解成以下任务：
1.	我们要确定哪些信息是需要分析及学习的（在机器学习中，我们称为“Feature”或“特征”）。
2.	我们要确定哪些是答案信息（即日后我们要猜的是什么，在监督类型的机器学习中，我们称为“Label”或“标签”）

对于第·1个小任务，装箱计算主要是依据顾客订购商品及商品size决定装箱方案。所以顾客订购什么商品，商品的规格（size）是我们要分析及学习的特征。不过难题是每个客人订购品种的数量是不一样，所以不同订单的“特征”数量是不一样的，怎么才能做到统一？我想到的办法是把所有产品的规格拆分成不同范围，例如长度拆分成0cm~5cm、5cm~10cm、10~15cm…等等，统计每张订单在不同范围的商品数量。这样即使订单下订的品种及品种数量不一，也能统一一堆Feature(如熟悉数据库的同学可以理解成字段或列)。
另外，考虑到原始数据只有长、宽、高的数据，而我们在装箱计算的过程中更有机会使用到体积数据，所以我们在长宽高的基础上再整合了体积类的字段。

对于第2个小任务，明显地，订单的装箱方案是我们日后要猜的信息，所以这是我们要学习的“答案”（“Label”或“标签”）。我们会把不同的装箱方案定义成不同的选项答案。例如所有只使用1个M类型箱子装放的订单，它们的“答案”是一样的；所有使用1·个L箱+2个M箱的订单，它们的“答案”又是一样的。所以我们要找出原始数据中所有不同组合的装箱方案，并为它们定义一个方案编号（例如装箱方案1定义为使用一个M箱；方案2位使用1·个L箱+2个M箱等等）。之后我们面对新的未知答案的订单，我们就是要“猜”哪个方案编号可能性最大。

所以我们期望整理后的数据长这个样子：
其中一行表示一张订单，字段l0/l1/l2/l3…代表此订单订购了不同长度范围的商品数量；字段w0/w1/w2/w3…代表此订单订购了不同宽度范围的商品数量；同样地hxx和sxx分别表示订购了不同高度及体积范围的商品数量。其中长度从0~800mm拆分成32份，每25mm一份，例如l0代表0~25mm，l1代表25~50mm；宽度、高度的范围范围是0~480mm和0~560mm，每20mm一份；对于体积，我没有想到使用特别的一个数字进行划分，就简单地，有多少类体积，就划分多少份。（处理够粗暴的！）
而最后一个字段label是该订单属于哪个装箱方案（为装箱方案编号）。

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/data_after.PNG)

下图列出了完整的字段：

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/feature_columns.PNG)

我们的装箱方案及方案编号对照长这个样子：

例如装箱方案编号为11的代表是使用了M箱2个，XS箱1个。
我们一共有7类不同的箱子（L、L2、M、S、X、XS、XS3）。
总过有63个不同的装箱组合方案。方案编号从0到62（注：下图未截完整）。

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/solution_label.PNG)


上面整理数据、对数据进行预处理要花的时间很长，代码量也有一定，虽然此部分占据了我整体处理的60~70%时间，虽然数据预处理是机器学习重要的一环，不过我不打算再在此文细说，我对此部分定义是繁琐，不过不算是新鲜或难处理。我相信有一定编程经验的同学也会处理，且此部分处理可以使用不同的编程工具，SQL、Python、Java、Excel等等都可以。本文最后会列出以Python处理的完整代码，有兴趣的同学可以参考。

接着，我们需要考虑使用什么算法对此·部分数据进行学习产生模型，还有怎么评价模型的好坏。

我使用的是决策树对已有数据进行学习及未来数据进行预测。其实使用决策树是否一个好的选择，我一开始并不知道，只是想到它简单、且可解释性强，所以就先试试它。
至于如何评价得到的模型好坏，我的做法更简单，把已有的数据拆分成7/3比例两部分，7 的部分是训练集，用于训练产生模型，让剩余3的部分对模型进行验证，验证模型的泛化能力，即考验其遇到新数据时候的表现如何，能否预测得准确。
以上是我刚开始的想法。

好~！贴上代码。

简单对代码逻辑进行解释：
1.	df_findata是我们整理数据后的完整数据集（注：数据量不算太多，只有14113条记录，可能算是Toy级别的数据量，只是玩玩，别太认真），类型为DataFrame。
2.	然后将数据拆分成按7/3比例进行拆分成train和test两个数据集。我使用了sklearn中的cross_validation工具进行拆分。注意：我们对random_stat由始至终都设置为0（可以设置其他固定的数字，但不可以是None喔），这样我们前后处理得到的训练集和验证集皆会是一模一样。（后面程序还会对模型进行优化，我希望再次测试它预测准确率的时候使用同一套训练集和验证集，这样前后标准都是一致的）。
3.	跟着，我们对训练集(train)和验证集(test)分别拆分出它的特征(train_x, test_x)和标签(train_y,test_y)。特征列是从l0到s243等众多列组成；标签就是label列。
4.	我使用的是sklearn的决策树工具。sklearn是机器学习的神器！包含了主流的机器学习算法，如线性回归、逻辑回归、决策树、SVM、K近邻等等众多监督学习、非监督学习等算法都包含之，不但如此，机器学习的流程中，训练和预测只是占流程的一小部分，还有数据预处理，模型评估等步骤，它都提供了丰富的工具。使用简单！它还有一些入门级的数据集可供学习使用。
5.	对训练集进行训练（clf.fit(train_x,train_y)）。
6.	对验证集进行打分，其实就是给出新的数据（test_x），标准答案是test_y，看看模型能答对多少了。
7.	最后打印出分数(即准确率)为76.76%!

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/result1.PNG)

结果还不算太差。总过有63个装箱方案啊！你想想，如果是你考试，每一题都有63个选项供你选择，准确率还能达到7成多！！所以还好还好。（自我安慰一下）

以上是我们的baseline模型。可以歇一会。


休息后，我们继续撸，继续优化。
我想到的是我们怎么会有63个装箱方案这么多啊？！
统计一下每种装箱方案的分布情况，发现原来只有7类常用的装箱方案，占到总案例数差不多94%，它们的方案编号分别为3/1/6/0/20/24/22。而剩余56类方案只占6%，剩余的类别太散了！我想能否忽略这些少量的方案，将这56类都归并为2~4类，例如如果我们越大的箱子，结算到配送商的费用越高，那么如果有以下两个装箱方案：(1).大箱1个，小小箱1个  (2).大箱1个，小小箱2个。我们就将这两类合并成1个装箱方案类别，因为它们有相同且费用占比很高的“大箱”。这样处理会减少机器分类的选项，虽然忽略了细微的差别，但是却可能提高准确率。

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/solution_precentage.png)

嗯，先试试就直接将剩余的类别归并到一类中，这样处理是最粗暴简单的，更好地，应该像上面的思路依据箱类型占据结算费用的占比拆分成2~4类。不过为了让我更快地看到成效，先试试都归并到一类中去吧。

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/result2.PNG)

如上图，我们把装箱方案不是类别为3/1/6/0/20/24/22的案例归并为-1类别，然后再统计一次各类别的分布，其他类别（-1）大约占6.16%

已经迫不期待再执行一次学习及打分了~！

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/treat_other_solutuion_result.PNG)

准确率大约提高了2%！达到78.50%。

刚才我们使用的是决策树模型。好像还没有解释什么是决策树。大概就是系统通过学习后，产生树模型，树模型长得像一个二叉树，在预测新数据的时候，数据自顶向下走一次树的分支，直到停留在某个最后的叶子节点，该叶子节点就是预测的“答案”。
我使用了一个网上获取例子，说明树模型的运作。
至于系统是如何产生树模型的，大概是通过统计每个feature，找到最能分辨某个类别的feature，就作为一个支点。类似如此。举个简单的例子，假如我们需要对人进行分类，分辨出男生还是女生，有两个Feature，Feature1是是否短头发，Feature2是身高。训练集中100个案例里，短头发的男生有95个，短头发的女生只有10个，而男生身高在170以上的有70位，女生在170以上的有30位。那明显地，我们会选择是否短头发作为第1个辨识的特征，如果在预测的时候，知道某同学是短头发，我们很肯定的说这个是男生了。所以第1节点就是头发的特征。接着如果头发不能辨识，我们再使用身高作为下一个节点。通俗理解它的原理就是这样。本文不是专门说明机器学习算法的原理，所以点到即止。大家可以继续百度一下。

我们使用决策树只是一棵树。但是只有一棵树，可能因为训练集中有一些异常数据，把坏的Feature也学习到了，导致在预测新数据的时候会出现错误，在术语上说就是“过拟合”。我理解成过度地学习了训练集数据，没有学到通行，泛化性不好。我们有另外一个叫随机森林的算法，对比起只有一颗树（或称为一个学习器）决策，“森林”就是有好多棵树（或称为多个学习器）一起决策，多棵树产生预测结果，对结果进行投票决定。在产生每一棵决策树的过程，系统不会把所有训练数据都学习，而是随机抽取部分数据，而且也不是每次使用所有特征进行学习，而是随机选取一些特征，而忽略一小部分特征。这样的好处显然易见的，我们相信大部分数据都是正常的数据，数据中大部分的特征都是正常的数据，只有少部分是异常或难以区分的数据，所以随机抽取的好处是，增大抽取到好数据的机会。即使产生了一些不正常的“树”，可能也只是一少部分的答案是不正确，但是凭着“群众的眼睛是雪亮的”，所以结果可能还是正确的。以此提高预测的准确率。

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/forest1.PNG)


提高那么一点点。79.24。

在上面的代码中，可以留意到我们的RandonForestClassifier是没有使用太多参数的，都只是使用默认参数。跟着，我们尝试搜索最优的参数。随机森林中影响可能较大的就是有多少棵树进行决策。例如10棵？还是100棵？还是更多。友时也不是越多越好。

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/grid_search_1.PNG)


上图highline的部分是关键的代码和结果输出。大概的意思就是我们要搜索“n_estimators”的参数，从10到141中进行搜索，每次增10（10,20,30..140）进行搜索。输出结果上显示当该值设置为140是最优的结果。（你可能有疑问，为什么不是更高的数字，因为我搜索的空间最高也是140。这是因为我第1次是搜索10-200的，但是又忘记截屏，而每次执行搜索的时候，运算时间太长了，所以再写文章时候截屏就简单地示例一下代码）

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/grid_search_1_result.PNG)

同样的代码，只是增加了n_estimators=140再执行一遍，结果是82.66%，提高了3个点！！

由于时间关系，我有再尝试对其他参数进行调优，不过效果不算明显，而且运行时间长，算是失败的操作，可能对参数调优还未能掌握得太好，所以也就不列在本文献丑了。

我一直都怀疑自己对长宽高的分类是否一个好办法。长宽高是一系列的连续值，例如把粗暴地把长度按25一份进行划分是否合适，更细的如12.5一份，或更大的如50一份哪个更好？这些一直都是我的疑问。除了划分范围我也没有想到更好的办法，所以我还是使用划分的办法。接下来，我尝试将其划分更细或更粗，看看效果怎样。

（由于划分那段代码是在数据预处理那段，而那段逻辑太长，且不是本文重点，所以我没有在此贴出）

我尝试把原来长度25mm一个间隔，宽度和高度20mm一个间隔，往更细的精度调整，调整成长度12.5mm，宽度和高度10mm，体积维持一样。列变多了好多如下图，再跑一遍，结果从刚才最优的82.66%掉到了79.17%！！

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/expand_length_columns.PNG)

调整更精细不行，为什么呢？难度是因为调整更细了，系统学习到和关注到更多细微之处，从而降低了它的泛化能力，产生过拟合？调细不行，那我要调粗一点更好？嗯试试吧。接着我再把长度调整成50mm一份，宽度和高度调整成40mm一份，体积维持一样。列变少了如下图。再试！！结果从刚才最优的82.66%提高到了84.37%！！

![Mou icon](https://raw.githubusercontent.com/jayliangdl/jayliangdl.github.io/master/column_change.png)

到此，我没有再继续优化，不过有几个优化点是有想法的：
1.	我们当前把剩余不通常出现的56个分类只分到1类，这肯定会导致错误率高一些。因为通常不出现的分类要么要用顾客订购了很多商品，体积可能很大，导致使用了一些不常用的箱子；要么订购了体积很小的商品。所以就把它们分为一类是不合理的。所以可以考虑分成多几类。
2.	我们当前尝试使用了决策树和随机森林，其他机器学习算法对它进行学习及预测是否更好，例如SVM，逻辑回归等等是否更好？